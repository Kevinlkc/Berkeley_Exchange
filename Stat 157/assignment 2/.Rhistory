MC = 2000
extreme = rep(0,3)
MC = 2000
extreme = rep(0,3)
obsValue <- stat_SRE(data$nodegr, data$treat, data$re78)
obsValue
for (i in 1:MC){
mcStat = stat_SRE(data$nodegr, permute(data$nodegr, data$treat), data$re78)
for (j in 1:3){
if (abs(mcStat[j]) > abs(obsValue[j])){
extreme[j] = extreme[j] + 1
}
}
}
# Tidy display of our result
display <- data.frame("Taus" = extreme[1]/MC, "V" = extreme[2]/MC, "Aligned Rank" = extreme[3]/MC)
display
# Step 4: Compare our results with the CRE
z <- lalonde$treat
y <- lalonde$re78
# Monte-Carlo Simulation of data
MC = 2000
Tauhat   = rep(0, MC)
Student  = rep(0, MC)
Wilcox   = rep(0, MC)
Ks       = rep(0, MC)
tau = t.test(y ~ z, var.equal = TRUE)$statistic
t = t.test(y ~ z, var.equal = FALSE)$statistic
w = wilcox.test(y ~ z)$statistic
ks = ks.test(y[z == 1], y[z == 0])$statistic
extreme_tau = 0
extreme_t = 0
extreme_w = 0
extreme_ks = 0
for(mc in 1:MC){
zperm = sample(z)
temptau = t.test(y ~ zperm, var.equal = TRUE)$statistic
tempt = t.test(y ~ zperm, var.equal = FALSE)$statistic
tempw = wilcox.test(y ~ zperm)$statistic
tempks = ks.test(y[zperm == 1], y[zperm == 0])$statistic
if (abs(temptau) > abs(tau)){
extreme_tau <- extreme_tau + 1
}
if (abs(tempt) > abs(t)){
extreme_t <- extreme_t + 1
}
if (abs(tempw) < abs(w)){
extreme_w <- extreme_w + 1
}
if (abs(tempks) > abs(ks)){
extreme_ks <- extreme_ks + 1
}
}
extreme_tau / MC
# Tidy display of our result
display <- data.frame("Tau" = extreme_tau/MC, "t" = extreme_t/MC, "Wilcoxon" = extreme_w/MC, "KS" = extreme_ks)
display
# Tidy display of our result
display <- data.frame("Tau" = extreme_tau/MC, "t" = extreme_t/MC, "Wilcoxon" = extreme_w/MC, "KS" = extreme_ks / MC)
display
# Part 2: Neymanian Inference
print(c ("Ts = ", obsValue[1]))
# Part 2: Neymanian Inference
print(c ("The point estimator is = ", obsValue[1]))
# Part 2: Neymanian Inference
print(c ("The point estimator is", obsValue[1]))
var_neyman <- function(stratum, treatment, Y){
V = 0
for(i in 1:length(unique(stratum))){
tempy = y[stratum == i]
tempt = treatment[stratum == i]
n = length(tempy)
y0 = tempy[tempt == 0]
y1 = tempy[tempt == 1]
V = V + (length(y0)/n)^2 * (sd(y0)/length(y0) + sd(y1)/length(y1))
}
}
var_neyman(data$race, data$treat, data$re78)
var_neyman(data$race, data$treat, data$re78)
temp <- var_neyman(data$race, data$treat, data$re78)
# Part 1: Fisher Randomization test
# Step 0: Some data-cleaning presumed here as I'm implementing my own function of SRE
library(Matching)
data <- lalonde
data <- data %>%
mutate(race = ifelse(black==1, 1, 0)) %>%
mutate(race = ifelse(hisp == 1, 2, race))
data <- data[,c(-3,-4)]
data$race <- data$race + 1
data <- data %>%
arrange(by = race)
# Part 2: Neymanian Inference
print(c ("The point estimator is", obsValue[1]))
var_neyman <- function(stratum, treatment, Y){
V = 0
for(i in 1:length(unique(stratum))){
tempy = y[stratum == i]
tempt = treatment[stratum == i]
n = length(tempy)
y0 = tempy[tempt == 0]
y1 = tempy[tempt == 1]
V = V + (length(y0)/n)^2 * (sd(y0)/length(y0) + sd(y1)/length(y1))
}
return(V)
}
temp <- var_neyman(data$race, data$treat, data$re78)
temp
library(Matching)
data(lalonde)
z = lalonde$treat
y = lalonde$re78
## Neymanian inference
n1= sum(z)
n0= length(z) - n1
tauhat = mean(y[z==1]) - mean(y[z==0])
vhat   = var(y[z==1])/n1 + var(y[z==0])/n0
sehat  = sqrt(vhat)
tauhat
sehat
sreVar <- var_neyman(data$race, data$treat, data$re78)
# Part 1: Fisher Randomization test
# Step 0: Some data-cleaning presumed here as I'm implementing my own function of SRE
library(Matching)
data <- lalonde
penndata = read.table("Penn46_ascii.txt")
head(penndata)
z = penndata$treatment
penndata$duration = log(penndata$duration)
y = lm(duration ~ .-treatment, data = penndata)$residuals
View(penndata)
penndata <- penndata %>%
mutate(quarter = quarter + 1) %>%
arrange(by = quarter)
obsValue = stat_SRE(penndata$quarter, penndata$treatment, y)
obsValue[1]
SRE_adjusted <- var_neyman(penndata$quarter, penndata$treatment, y)
SRE_adjusted
Neyman_SRE = function(z, y, x)
{
xlevels = unique(x)
K       = length(xlevels)
PiK     = rep(0, K)
TauK    = rep(0, K)
varK    = rep(0, K)
for(k in 1:K)
{
xk         = xlevels[k]
zk         = z[x == xk]
yk         = y[x == xk]
PiK[k]     = length(zk)/length(z)
TauK[k]    = mean(yk[zk==1]) - mean(yk[zk==0])
varK[k]    = var(yk[zk==1])/sum(zk) +
var(yk[zk==0])/sum(1 - zk)
}
return(c(sum(PiK*TauK), sum(PiK^2*varK)))
}
penndata = read.table("Penn46_ascii.txt")
head(penndata)
z = penndata$treatment
y = log(penndata$duration)
block = penndata$quarter
est = Neyman_SRE(z, y, block)
est[1]
sqrt(est[2])
est[2]
# Interval estimation
print(c("[",obsValue[1] - SRE_adjusted*1.96,",",obsValue[1] + SRE_adjusted*1.96,"]"))
# Interval estimation
print(paste("[",obsValue[1] - SRE_adjusted*1.96,",",obsValue[1] + SRE_adjusted*1.96,"]"), sep = "")
print(paste("[",est[1]-1.96*sqrt(est[2]),",",est[1]+sqrt(est[2]),"]"))
library(ggplot2)
library(tidyr)
library(tidyverse)
library(dplyr)
# Model H0: y = coef_0
# Model H1: y = coef_1a + coef_1b
n_out <- 20000
epsilon <- rnorm(n_out, 0, 0.1)
# For each iteration, I'd like to record the following values
coef_0 <- vector()
coef_1a <- vector()
coef_1b <- vector()
MSE_0 <- rep(0, 500)
MSE_1 <- rep(0, 500)
# Here we randomly draw a test set
set.seed(12345)
x_out <- runif(n_out, min = -1, max = 1)
y_out <- x_out^2 + epsilon
# Fit the model with 2 training sets, and calculate the MSE of each model we fit
for (i in 1:500){
x <- runif(n = 2, min = -1, max = 1)
y <- x^2 + epsilon
coef_0 <- c(coef_0, (y[1]+y[2])/2)
coef_1a <- c(coef_1a, y[1] - x[1]*(y[2]-y[1])/(x[2]-x[1]))
coef_1b <- c(coef_1b, (y[2]-y[1])/(x[2]-x[1]))
for (j in 1:n_out){
MSE_0[i] = MSE_0[i] + ((y_out[j] - coef_0[i])^2)/n_out
MSE_1[i] = MSE_1[i] + ((y_out[j] - coef_1a[i] - coef_1b[i] * x_out[j])^2)/n_out
}
}
# Here's the code for the H_0 plot
plot_data <- data.frame(x = x_out, y = y_out)
plot_data %>%
ggplot() + theme_bw() +
geom_point(aes(x = x, y = y), color = 'blue', alpha = 0.02) +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_hline(yintercept = coef_0, alpha = 0.05) +
geom_hline(yintercept = mean(coef_0), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 0"
)
# Here's the code for the H_1 plot
plot_data %>%
ggplot() + theme_bw() +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_point(aes(x = x, y = y), color = 'blue', alpha = 0.02) +
geom_abline(intercept = coef_1a, slope = coef_1b, alpha = 0.05) +
geom_abline(intercept = mean(coef_1a), slope = mean(coef_1b), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 1"
)
# To verify the bias-variance trade-off rigorously, we examine the first model
OverallMSE_0 <- mean(MSE_0)
bias <- vector()
variance <- vector()
for (i in 1:20000){
bias[i] <- (mean(coef_0) - y_out[i])^2
}
bias_0 <- mean(bias)
for (i in 1:500){
variance[i] <- (mean(coef_0) - coef_0[i])^2
}
variance_0 <- mean(variance)
# Display it tidily
model_0 <- data.frame("OverallMSE" = OverallMSE_0, "Bias" = bias_0, "Var" = variance_0)
model_0
# If the decomposition is correct, it shall return 0
model_0$OverallMSE - model_0$Bias - model_0$Var
OverallMSE_1 <- mean(MSE_1)
bias <- vector()
variance <- rep(0, n_out)
for (i in 1:20000){
bias[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - y_out[i])^2
}
bias_1 <- mean(bias)
for (i in 1:500){
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
for (i in 1:500){
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
OverallMSE_1 <- mean(MSE_1)
bias <- vector()
variance <- rep(0, n_out)
for (i in 1:20000){
bias[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - y_out[i])^2
}
bias_1 <- mean(bias)
for (i in 1:500){
print(i)
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
View(display)
variance_1 <- mean(variance)
# Display it tidily
model_1 <- data.frame("OverallMSE" = OverallMSE_1, "Bias" = bias_1, "Var" = variance_1)
model_1
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var
library(ggplot2)
library(tidyr)
library(tidyverse)
library(dplyr)
# Model H0: y = coef_0
# Model H1: y = coef_1a + coef_1b
n_out <- 20000
epsilon <- 0
# For each iteration, I'd like to record the following values
coef_0 <- vector()
coef_1a <- vector()
coef_1b <- vector()
MSE_0 <- rep(0, 500)
MSE_1 <- rep(0, 500)
# Here we randomly draw a test set
set.seed(12345)
x_out <- runif(n_out, min = -1, max = 1)
y_out <- x_out^2 + epsilon
# Fit the model with 2 training sets, and calculate the MSE of each model we fit
for (i in 1:500){
x <- runif(n = 2, min = -1, max = 1)
y <- x^2 + epsilon
coef_0 <- c(coef_0, (y[1]+y[2])/2)
coef_1a <- c(coef_1a, y[1] - x[1]*(y[2]-y[1])/(x[2]-x[1]))
coef_1b <- c(coef_1b, (y[2]-y[1])/(x[2]-x[1]))
for (j in 1:n_out){
MSE_0[i] = MSE_0[i] + ((y_out[j] - coef_0[i])^2)/n_out
MSE_1[i] = MSE_1[i] + ((y_out[j] - coef_1a[i] - coef_1b[i] * x_out[j])^2)/n_out
}
}
# Here's the code for the H_0 plot
plot_data <- data.frame(x = x_out, y = y_out)
plot_data %>%
ggplot() + theme_bw() +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_hline(yintercept = coef_0, alpha = 0.05) +
geom_hline(yintercept = mean(coef_0), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 0"
)
# Here's the code for the H_1 plot
plot_data %>%
ggplot() + theme_bw() +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_abline(intercept = coef_1a, slope = coef_1b, alpha = 0.1) +
geom_abline(intercept = mean(coef_1a), slope = mean(coef_1b), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 1"
)
# To verify the bias-variance trade-off rigorously, we examine the first model
OverallMSE_0 <- mean(MSE_0)
bias <- vector()
variance <- vector()
for (i in 1:20000){
bias[i] <- (mean(coef_0) - y_out[i])^2
}
bias_0 <- mean(bias)
for (i in 1:500){
variance[i] <- (mean(coef_0) - coef_0[i])^2
}
variance_0 <- mean(variance)
# Display it tidily
model_0 <- data.frame("OverallMSE" = OverallMSE_0, "Bias" = bias_0, "Var" = variance_0)
model_0
# If the decomposition is correct, it shall return 0
model_0$OverallMSE - model_0$Bias - model_0$Var
# Similarly, we can do this to the second model
OverallMSE_1 <- mean(MSE_1)
bias <- vector()
variance <- rep(0, n_out)
for (i in 1:20000){
bias[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - y_out[i])^2
}
bias_1 <- mean(bias)
for (i in 1:500){
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
variance_1 <- mean(variance)
# Display it tidily
model_1 <- data.frame("OverallMSE" = OverallMSE_1, "Bias" = bias_1, "Var" = variance_1)
model_1
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var
# Model H0: y = coef_0
# Model H1: y = coef_1a + coef_1b
n_out <- 20000
epsilon <- rnorm(n_out, 0, 0.1)
# For each iteration, I'd like to record the following values
coef_0 <- vector()
coef_1a <- vector()
coef_1b <- vector()
MSE_0 <- rep(0, 500)
MSE_1 <- rep(0, 500)
# Here we randomly draw a test set
set.seed(12345)
x_out <- runif(n_out, min = -1, max = 1)
y_out <- x_out^2 + epsilon
# Fit the model with 2 training sets, and calculate the MSE of each model we fit
for (i in 1:500){
x <- runif(n = 2, min = -1, max = 1)
y <- x^2 + epsilon
coef_0 <- c(coef_0, (y[1]+y[2])/2)
coef_1a <- c(coef_1a, y[1] - x[1]*(y[2]-y[1])/(x[2]-x[1]))
coef_1b <- c(coef_1b, (y[2]-y[1])/(x[2]-x[1]))
for (j in 1:n_out){
MSE_0[i] = MSE_0[i] + ((y_out[j] - coef_0[i])^2)/n_out
MSE_1[i] = MSE_1[i] + ((y_out[j] - coef_1a[i] - coef_1b[i] * x_out[j])^2)/n_out
}
}
# Here's the code for the H_0 plot
plot_data <- data.frame(x = x_out, y = y_out)
plot_data %>%
ggplot() + theme_bw() +
geom_point(aes(x = x, y = y), color = 'blue', alpha = 0.02) +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_hline(yintercept = coef_0, alpha = 0.05) +
geom_hline(yintercept = mean(coef_0), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 0"
)
# Here's the code for the H_1 plot
plot_data %>%
ggplot() + theme_bw() +
geom_smooth(aes(x = x, y = y), color = 'blue') +
geom_point(aes(x = x, y = y), color = 'blue', alpha = 0.02) +
geom_abline(intercept = coef_1a, slope = coef_1b, alpha = 0.05) +
geom_abline(intercept = mean(coef_1a), slope = mean(coef_1b), color = 'red', size = 1) +
scale_y_continuous(expand = c(0.001, 0.001)) +
scale_x_continuous(expand = c(0.001, 0.001)) +
labs(
title = "Hypothesis 1"
)
# To verify the bias-variance trade-off rigorously, we examine the first model
OverallMSE_0 <- mean(MSE_0)
bias <- vector()
variance <- vector()
for (i in 1:20000){
bias[i] <- (mean(coef_0) - y_out[i])^2
}
bias_0 <- mean(bias)
for (i in 1:500){
variance[i] <- (mean(coef_0) - coef_0[i])^2
}
variance_0 <- mean(variance)
# Display it tidily
model_0 <- data.frame("OverallMSE" = OverallMSE_0, "Bias" = bias_0, "Var" = variance_0)
model_0
# If the decomposition is correct, it shall return 0
model_0$OverallMSE - model_0$Bias - model_0$Var
OverallMSE_1 <- mean(MSE_1)
bias <- vector()
variance <- rep(0, n_out)
for (i in 1:20000){
bias[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - y_out[i])^2
}
bias_1 <- mean(bias)
for (i in 1:500){
print(i)
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
variance_1 <- mean(variance)
# Display it tidily
model_1 <- data.frame("OverallMSE" = OverallMSE_1, "Bias" = bias_1, "Var" = variance_1)
model_1
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var
model_0
for (i in 1:20000){
bias[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - x_out[i]^2)^2
}
# Display it tidily
model_1 <- data.frame("OverallMSE" = OverallMSE_1, "Bias" = bias_1, "Var" = variance_1)
model_1
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var
bias_1 <- vector()
variance <- rep(0, n_out)
for (i in 1:20000){
bias_1[i] <- (mean(coef_1a) + mean(coef_1b)*x_out[i] - x_out[i]^2)^2
}
bias_1 <- mean(bias)
for (i in 1:500){
print(i)
for (j in 1:n_out){
variance[i] = variance[i] + ((mean(coef_1a) + mean(coef_1b)*x_out[j] - coef_1a[i] - coef_1b[i]*x_out[j])^2)/500
}
}
# Display it tidily
model_1 <- data.frame("OverallMSE" = OverallMSE_1, "Bias" = bias_1, "Var" = variance_1)
model_1
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var
# If the decomposition is correct, it shall return 0
model_1$OverallMSE - model_1$Bias - model_1$Var - 0.01
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(foreign)
library(readxl)
# Step 1: Pretend that the SRE is done by blocking race
MC = 2000
# Baseline Model with NO Strata
# Compare it with the normal complete randomized experiment
# Part 1: FRT
# Step 4: Compare our results with the CRE
data("lalonde")
z <- lalonde$treat
# Baseline Model with NO Strata
# Compare it with the normal complete randomized experiment
# Part 1: FRT
# Step 4: Compare our results with the CRE
library(Matching)
data("lalonde")
z <- lalonde$treat
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(foreign)
library(readxl)
rank(1,1,2,3)
rank(c(1,1,2,3))
