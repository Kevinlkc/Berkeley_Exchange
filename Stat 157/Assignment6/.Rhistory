D <- ifelse(card$educ > 12, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's significantly different from zero.
# 2/ If we use a different threshold for the treatment indicator
card <- read.csv("card.csv")
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 16, 1, 0)
est = IV_Wald(Z, D, Y)
estVar = IV_Wald_delta(Z, D, Y)
print(paste("The (Wald) point estimate of the treatment effect for logwage is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
card <- na.omit(card)
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 16, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's still significantly different from zero.
card <- na.omit(card)
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 16, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's still significantly different from zero.
# 2SLS
Dhat    = lm(D ~ Z + X)$fitted.values
# 2SLS
TSLS <- function(Z, D, Y, X){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(LATE, stderr)
}
TSLS(Z, D, Y, X)
??hccm
?hccm
install.packages("car")
library(car)
TSLS(Z, D, Y, X)
# 2SLS
TSLS <- function(Z, D, Y, X){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list(LATE, stderr))
}
TSLS(Z, D, Y, X)
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, "and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
# 2SLS
TSLS <- function(Z, D, Y, X){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, "and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
scatterplotMatrix(card)
scatterplotMatrix(educ, lwage)
attach(card)
scatterplotMatrix(educ, lwage)
detach(card)
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage))
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) +
geom_smooth(aes(x = card$educ, y = card$lwage))
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) +
geom_smooth(aes(x = card$educ, y = card$lwage))
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) +
geom_smooth(aes(x = card$educ, y = card$lwage))
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) +
geom_smooth(aes(x = card$educ, y = card$lwage))
# There's no clear indicator that the influence of education is non-linear
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) + theme_bw() +
geom_smooth(aes(x = card$educ, y = card$lwage, color = "maroon"))
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) + theme_bw() +
geom_smooth(aes(x = card$educ, y = card$lwage), color = "maroon")
data <- read.csv("EF.csv")
View(card)
View(data)
data <- read.csv("EF.csv")
# Baseline: If we analyze the data as the authors
Z = data[,1]
D = data[,2]
Y = data[,5] - 0.75*data[,4] - 0.25*data[,3]
# TSLS
TSLS(Z, D, Y)
# TSLS
TSLS(Z, D, Y)
# 2SLS
TSLS <- function(Z, D, Y, X=1){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
# TSLS
TSLS(Z, D, Y)
# 2SLS
TSLS <- function(Z, D, Y, X=0){
if (X == 0){X = rep(1, nrow(D))}
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, "and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
data <- read.csv("EF.csv")
# Baseline: If we analyze the data as the authors
Z = data[,1]
D = data[,2]
Y = data[,5] - 0.75*data[,4] - 0.25*data[,3]
# TSLS
TSLS(Z, D, Y)
# 2SLS
TSLS <- function(Z, D, Y, X=0){
if (X == 0){X = rep(1, length(D))}
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, "and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
# TSLS
TSLS(Z, D, Y)
# 2SLS
TSLS <- function(Z, D, Y, X=0){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, "and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
data <- read.csv("EF.csv")
# Baseline: If we analyze the data as the authors
Z = data[,1]
D = data[,2]
Y = data[,5] - 0.75*data[,4] - 0.25*data[,3]
# TSLS
TSLS(Z, D, Y)
# TSLS
TSLS_simple <- function(Z, D, Y){
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z)$fitted.values
tslsreg = lm(Y ~ Dhat)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
TSLS_simple(Z, D, Y)
# TSLS
TSLS_simple <- function(Z, D, Y){
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z)$fitted.values
tslsreg = lm(Y ~ Dhat)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS_simple(Z, D, Y)$LATE, "and the CI is [", TSLS_simple(Z, D, Y)$LATE - 1.96*TSLS_simple(Z, D, Y)$se,",",TSLS_simple(Z, D, Y)$LATE + 1.96*TSLS_simple(Z, D, Y)$se, "]", sep = ""))
library(ggplot2)
library(tidyverse)
library(tidyr)
library(dplyr)
library(car)
xdat <- read.csv("X.csv", header = T, sep = ",")
ydat <- read.csv(file="Y.csv", header = TRUE, sep = ",")
dat <- bind_cols(xdat, ydat)
names(dat)
dat <- dat %>%
filter(r52 == 1 & r130 == 1 & r208 == 1) %>%
mutate(w52 = ifelse(is.na(w52), 0, w52)) %>%
mutate(w130 = ifelse(is.na(w130), 0, w130)) %>%
mutate(w208 = ifelse(is.na(w208), 0, w208))
sum(is.na(dat))
dat <- na.omit(dat)
# 1. Without Covariates
Z <- dat %>%
select(assign)
D <- dat %>%
select(treat)
Y <- dat[,39:44]
X <- dat[,2:23]
IV_Wald = function(Z, D, Y)
{
tau_D = mean(D[Z==1]) - mean(D[Z==0])
tau_Y = mean(Y[Z==1]) - mean(Y[Z==0])
CACE  = tau_Y/tau_D
return(list(tau_D = tau_D, tau_Y = tau_Y,
CACE  = CACE))
}
## IV se via the delta method
IV_Wald_delta = function(Z, D, Y)
{
est         = IV_Wald(Z, D, Y)
AdjustedY   = Y - D*est$CACE
VarAdj      = var(AdjustedY[Z==1])/sum(Z) +
var(AdjustedY[Z==0])/sum(1 - Z)
return(sqrt(VarAdj)/abs(est$tau_D))
}
# IV wald estimation without covariates
for (i in 1:6)
{
est = IV_Wald(Z, D, Y[,i])
estVar = IV_Wald_delta(Z, D, Y[,i])
print(paste("The (Wald) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
}
IV_Lin = function(Z, D, Y, X)
{
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
tau_D = lm(D ~ Z + X + Z*X)$coef[2]
tau_Y = lm(Y ~ Z + X + Z*X)$coef[2]
names(tau_D) = NULL
names(tau_Y) = NULL
CACE  = tau_Y/tau_D
return(list(tau_D = tau_D, tau_Y = tau_Y,
CACE  = CACE))
}
## IV_adj se via the delta method
IV_Lin_delta = function(Z, D, Y, X)
{
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
est    = IV_Lin(Z, D, Y, X)
betaY1 = lm(Y ~ X, subset = (Z == 1))$coef[-1]
betaY0 = lm(Y ~ X, subset = (Z == 0))$coef[-1]
betaD1 = lm(D ~ X, subset = (Z == 1))$coef[-1]
betaD0 = lm(D ~ X, subset = (Z == 0))$coef[-1]
AdjustedY1   = Y - X%*%betaY1 -
(D - X%*%betaD1)*est$CACE
AdjustedY0   = Y - X%*%betaY0 -
(D - X%*%betaD0)*est$CACE
VarAdj       = var(AdjustedY1[Z==1])/sum(Z) +
var(AdjustedY0[Z==0])/sum(1 - Z)
return(sqrt(VarAdj)/abs(est$tau_D))
}
# 2. With Covariates
# IV wald estimation without covariates
for (i in 1:6)
{
est = IV_Lin(Z, D, Y[,i], X)
estVar = IV_Lin_delta(Z, D, Y[,i], X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
}
card <- read.csv("card.csv")
Y <- card$lwage
Z <- card$nearc2
D <- ifelse(card$educ > 12, 1, 0)
est = IV_Wald(Z, D, Y)
estVar = IV_Wald_delta(Z, D, Y)
print(paste("The (Wald) point estimate of the treatment effect for logwage is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's significantly different from zero.
# With covariates (Note that we're somehow arbitrarily dropping all the observations with na values. That's based on the assumption that the NA values are uncorrelated with either the treatment assigned or the treatment received. However, it is possible that this is not the case. Further investigation is needed for those data.)
# Note that we dropped all the data with south indicator 1 here, leading to NA values in the regression, so we drop them. We'll investigate the stability of our investigation in the later part of the analysis.
card <- na.omit(card)
Y <- card$lwage
Z <- card$nearc2
D <- ifelse(card$educ > 12, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's significantly different from zero.
# Stability of our analysis.
# 1/ if we use the 4 mile indicator instead of 2 mile
card <- read.csv("card.csv")
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 12, 1, 0)
est = IV_Wald(Z, D, Y)
estVar = IV_Wald_delta(Z, D, Y)
print(paste("The (Wald) point estimate of the treatment effect for logwage is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's still significantly different from zero.
card <- na.omit(card)
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 12, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# That's still significantly different from zero.
# 2/ If we use a different threshold for the treatment indicator
card <- read.csv("card.csv")
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 16, 1, 0)
est = IV_Wald(Z, D, Y)
estVar = IV_Wald_delta(Z, D, Y)
print(paste("The (Wald) point estimate of the treatment effect for logwage is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# The treatment effect is even stronger when the treatment indicator is whether a person attends grad school
card <- na.omit(card)
Y <- card$lwage
Z <- card$nearc4
D <- ifelse(card$educ > 16, 1, 0)
X <- card %>% select(-id, -nearc2, -nearc4, -educ, -lwage, -south66, -reg669)
est = IV_Lin(Z, D, Y, X)
estVar = IV_Lin_delta(Z, D, Y, X)
print(paste("The (covariate adjusted) point estimate of the treatment effect for ", colnames(Y)[i] ," is ", est$CACE, " and the confidence interval is [", est$CACE - 1.96*estVar,",",est$CACE + 1.96*estVar,"]", sep = ""))
# However, we observed a flip of sign when we adjust our results with covariates. That indicates the key to the increase in wage in not positively influenced by attending grad school, but some pre-treatment variables like family status. The data, in that sense, is very unstable.
# 2SLS
TSLS <- function(Z, D, Y, X=0){
X = as.matrix(X)
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z + X)$fitted.values
tslsreg = lm(Y ~ Dhat + X)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D, X)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS(Z, D, Y, X)$LATE, " and the CI is [", TSLS(Z, D, Y, X)$LATE - 1.96*TSLS(Z, D, Y, X)$se,",",TSLS(Z, D, Y, X)$LATE + 1.96*TSLS(Z, D, Y, X)$se, "]", sep = ""))
# That's no longer significantly different from zero!
ggplot() +
geom_point(aes(x = card$educ, y = card$lwage)) + theme_bw() +
geom_smooth(aes(x = card$educ, y = card$lwage), color = "maroon")
# There's no clear indicator that the influence of education is non-linear
data <- read.csv("EF.csv")
# Baseline: If we analyze the data as the authors
Z = data[,1]
D = data[,2]
Y = data[,5] - 0.75*data[,4] - 0.25*data[,3]
# TSLS
TSLS_simple <- function(Z, D, Y){
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z)$fitted.values
tslsreg = lm(Y ~ Dhat)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS_simple(Z, D, Y)$LATE, " and the CI is [", TSLS_simple(Z, D, Y)$LATE - 1.96*TSLS_simple(Z, D, Y)$se,",",TSLS_simple(Z, D, Y)$LATE + 1.96*TSLS_simple(Z, D, Y)$se, "]", sep = ""))
data <- read.csv("EF.csv")
Z*D
# D is not randomized.
mean(Y[Z == 1]) - mean(Y[Z == 0])
n(Y[Z == 1])
count(Y[Z == 1])
length(Y[Z == 1])
# with standard error
sqrt(sd(Y[Z == 1])^2 / length(Y[Z == 1]) + sd(Y[Z == 0])^2 / length(Y[Z == 0]))
# Note that D is not randomized. The difference in means between the treatment and control group is
mean(Y[Z == 1]) - mean(Y[Z == 0])
# with standard error
sqrt(sd(Y[Z == 1])^2 / length(Y[Z == 1]) + sd(Y[Z == 0])^2 / length(Y[Z == 0]))
# However, there could be non-compliance. Namely, those assigned to the treatment group do not neccesarily receive enough medicine.
# A possible solution is to define the "Compliance Level" as C3 - C4. Those who listens to our advice is more likely to gain a decrease in the cholesterol level. The suggestion was made prior to the treatment assignment. So we can view this either as a covariate or as an instrumental variable.
X <- data[,3] - data[,4]
Z = data[,1]
D = data[,2]
Y = data[,5] - 0.75*data[,4] - 0.25*data[,3]
X <- data[,3] - data[,4]
# However, there could be non-compliance. Namely, those assigned to the treatment group do not neccesarily receive enough medicine.
# A possible solution is to define the "Compliance Level" as C3 - C4. Those who listens to our advice is more likely to gain a decrease in the cholesterol level. The suggestion was made prior to the treatment assignment. So we can view this either as a covariate or as an instrumental variable.
Z = data[,1]
D = data[,2]
Y = data[,5]
X <- data[,3] - data[,4]
# 1. As a covariate, use Lin's regression adjustment
model <- lm(Y~ Z*D + X + Z*D*X)
model$coef['Z*D']
model$coef
# However, there could be non-compliance. Namely, those assigned to the treatment group do not neccesarily receive enough medicine.
# A possible solution is to define the "Compliance Level" as C3 - C4. Those who listens to our advice is more likely to gain a decrease in the cholesterol level. The suggestion was made prior to the treatment assignment. So we can view this either as a covariate or as an instrumental variable.
Z = data[,1]
D = data[,2]
Y = data[,5]
X <- data[,3] - data[,4]
# 1. As a covariate, use Lin's regression adjustment
model <- lm(Y~ Z:D + X + Z:D:X)
model$coef
model$coef["Z:D"]
sqrt(hccm(model, type = "hc0")[2, 2])
model$coef["Z:D"]
sqrt(hccm(model, type = "hc0")[2, 2])
model$coef["Z:D"]
print(paste("One percent of increase in the effective drug intake leads to a decrease of 0.47 in the cholesterol level, assuming unconfoundedness conditioning on the compliance level. The confidence interval is [", model$coef["Z:D"] - 1.96*sqrt(hccm(model, type = "hc0")[2, 2]),",",model$coefficients["Z:D"] + 1.96*sqrt(hccm(model, type = "hc0")[2, 2]), "]", sep = ""))
# 2. As an instrumental variable. Then we have to focus on those who receives the real treatment.
Z = data[,3] - data[,4]
D = data[,1] * data[,2]
Y = data[,5]
TSLS_simple <- function(Z, D, Y){
D = as.matrix(D)
Y = as.matrix(Y)
Z = as.matrix(Z)
Dhat    = lm(D ~ Z)$fitted.values
tslsreg = lm(Y ~ Dhat)
LATE <- coef(tslsreg)[2]
res.correct       = Y - cbind(1, D)%*%coef(tslsreg)
tslsreg$residuals = as.vector(res.correct)
stderr <- sqrt(hccm(tslsreg, type = "hc0")[2, 2])
return(list("LATE" = LATE, "se" = stderr))
}
print(paste("The point estimate of the causal effect is ", TSLS_simple(Z, D, Y)$LATE, " and the CI is [", TSLS_simple(Z, D, Y)$LATE - 1.96*TSLS_simple(Z, D, Y)$se,",",TSLS_simple(Z, D, Y)$LATE + 1.96*TSLS_simple(Z, D, Y)$se, "]", sep = ""))
?matrix
data.frame("Z" = c(1,1,0,0), "D" = c(1,1,1,0), Y = (1,1,0,0))
data.frame("Z" = c(1,1,0,0), "D" = c(1,1,1,0), "Y" = (1,1,0,0))
data.frame("Z" = c(1,1,0,0), "D" = c(1,1,1,0), "Y" = c(1,1,0,0))
data <- data.frame("Z" = c(1,1,0,0), "D" = c(1,1,1,0), "Y" = c(1,1,0,0))
Q <- cbind(data$D * data$Y, data$D*(1 - data$Y), data$Y*(1-data$D), data$D+data$Y - data$D * data$Y)
mean(Q[1:2,1]) - mean(Q[3,4, 1])
mean(Q[1:2,1]) - mean(Q[3:4, 1])
mean(Q[1:2,1]) - mean(Q[3:4,1])
mean(Q[1:2,2]) - mean(Q[3:4,2])
mean(Q[1:2,3]) - mean(Q[3:4,3])
mean(Q[1:2,4]) - mean(Q[3:4,4])
data <- data.frame("Z" = c(1,1,0,0), "D" = c(1,1,0,0), "Y" = c(0,0,1,1))
Q <- cbind(data$D * data$Y, data$D*(1 - data$Y), data$Y*(1-data$D), data$D+data$Y - data$D * data$Y)
mean(Q[1:2,1]) - mean(Q[3:4,1])
mean(Q[1:2,2]) - mean(Q[3:4,2])
mean(Q[1:2,3]) - mean(Q[3:4,3])
mean(Q[1:2,4]) - mean(Q[3:4,4])
data <- data.frame("Z" = c(1,1,0,0), "D" = c(1,1,0,0), "Y" = c(1,1,1,0))
Q <- cbind(data$D * data$Y, data$D*(1 - data$Y), data$Y*(1-data$D), data$D+data$Y - data$D * data$Y)
mean(Q[1:2,1]) - mean(Q[3:4,1])
mean(Q[1:2,2]) - mean(Q[3:4,2])
mean(Q[1:2,3]) - mean(Q[3:4,3])
mean(Q[1:2,4]) - mean(Q[3:4,4])
data <- data.frame("Z" = c(1,1,0,0), "D" = c(1,1,0,0), "Y" = c(1,1,0,0))
Q <- cbind(data$D * data$Y, data$D*(1 - data$Y), data$Y*(1-data$D), data$D+data$Y - data$D * data$Y)
mean(Q[1:2,1]) - mean(Q[3:4,1])
mean(Q[1:2,2]) - mean(Q[3:4,2])
mean(Q[1:2,3]) - mean(Q[3:4,3])
mean(Q[1:2,4]) - mean(Q[3:4,4])
data <- data.frame("Z" = c(1,1,0,0), "D" = c(1,1,1,0), "Y" = c(1,1,0,0))
Q <- cbind(data$D * data$Y, data$D*(1 - data$Y), data$Y*(1-data$D), data$D+data$Y - data$D * data$Y)
mean(Q[1:2,1]) - mean(Q[3:4,1])
mean(Q[1:2,2]) - mean(Q[3:4,2])
mean(Q[1:2,3]) - mean(Q[3:4,3])
mean(Q[1:2,4]) - mean(Q[3:4,4])
