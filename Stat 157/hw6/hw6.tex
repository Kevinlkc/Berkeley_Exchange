\documentclass[11pt]{article}
\usepackage[left=1in,top=1in,right=1in,bottom=1in,head=.1in,nofoot]{geometry}

\setlength{\footskip}{24pt} % Page number/footer spacing
\usepackage{setspace,url,bm,amsmath} % For double-spacing, URL font, math symbols

\usepackage{titlesec} % Section header formatting
\titlelabel{\thetitle.\quad} % Section header formatting
%\titleformat*{\section}{\bf\large\center\uppercase} % Section header formatting

\usepackage{graphicx} % Graphics scaling
\usepackage{bbm, amssymb}
\usepackage{latexsym}
\usepackage{caption}
\usepackage[margin=20pt]{subcaption}
\usepackage{hyperref, enumerate}
\usepackage[all,import]{xy}

\usepackage{hyperref}


\usepackage[table]{xcolor}
%\newcommand\x{\times}
%\newcommand\y{\cellcolor{green!10}}
\newcommand\y[1]{%
  \colorbox{green!10}{$#1$}%
}
\newcommand{\GG}[1]{}

\usepackage{amsthm}
%\usepackage{undertilde}
\usepackage{comment}
\theoremstyle{definition}
\newtheorem{assumption}{Assumption}
\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{exercise}{Exercise}
\newtheorem{example}{Example}
\newtheorem{excont}{Example}
\renewcommand{\theexcont}{\theexample}

\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem*{corollary*}{Corollary}




\usepackage{natbib} % ASA citation style
\bibpunct{(}{)}{;}{a}{}{,} % ASA citation style

\renewcommand{\refname}{REFERENCES} % Capitalize bibliography section header
\usepackage{etoolbox} % Bibliography underfull/overfull box fix
\apptocmd{\sloppy}{\hbadness 10000\relax}{}{} % Bibliography underfull/overfull box fix

\usepackage{color}
\usepackage{listings}


\DeclareMathOperator*{\Med}{Med}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}


\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\def\letas{\mathrel{\mathop{=}\limits^{\triangle}}}
\def\ind{\begin{picture}(9,8)
         \put(0,0){\line(1,0){9}}
         \put(3,0){\line(0,1){8}}
         \put(6,0){\line(0,1){8}}
         \end{picture}
        }
\def\nind{\begin{picture}(9,8)
         \put(0,0){\line(1,0){9}}
         \put(3,0){\line(0,1){8}}
         \put(6,0){\line(0,1){8}}
         \put(1,0){{\it /}}
         \end{picture}
    }

\def\AVar{\text{AsyVar}}
\def\Var{\text{var}}
\def\var{\text{var}}
\def\Cov{\text{cov}}
\def\cov{\text{cov}}
\def\sumn{\sum_{i=1}^n}
\def\summ{\sum_{j=1}^m}
\def\convergeas{\stackrel{a.s.}{\longrightarrow}}
\def\converged{\stackrel{d}{\longrightarrow}}
\def\convergep{\stackrel{p}{\longrightarrow}}
\def\iidsim{\stackrel{i.i.d.}{\sim}}
\def\indsim{\stackrel{ind}{\sim}}
\def\N{\mathcal{N}}
\def\d{\textup{d}}
\def\KL{\textsc{KL}}
\def\obs{\textnormal{obs}}
\newcommand{\pr}{\textnormal{pr}}
\def\FRT{\text{Fisher randomization test}}
\def\asim{\stackrel{\cdot}{\sim}}
\def\DCE{\textsc{DCE}}

\begin{document}
\doublespacing
\title{\bf  Problem Set 6\\
Due December 2nd, 6:30 pm} 
\date{}
\maketitle

 
\section{Instrumental variable inequalities}

Give an example in which all the instrumental variable inequalities hold and another example in which not all the instrumental variable inequalities hold. You only need to specify the joint distribution of $(Z,D,Y)$ with binary $Z$ and $D$. 


\section{Numerical equivalence of the indirect least squares and two-stage least squares estimators (Stat 260 only)}


Consider the following canonical regression with one endogenous regressor $D$ and one instrumental variable $Z$:
\begin{eqnarray*}
Y &=& \tau D + X \beta + \varepsilon_1,\\
D &=& \alpha  Z + X\gamma  +  \varepsilon_2,
\end{eqnarray*}
where $Y, D, Z, \varepsilon_1, \varepsilon_2$ are $n\times 1$ vectors, and $X$ is an $n\times p$ matrix. If $D$ is endogenous, then the OLS fit for the first equation gives a biased estimator for $\tau$. Instead, we can use either the indirect least squares or the two-stage least squares estimator. 

The indirect least squares estimator has three steps: first, fit the OLS of $Y$ on $Z$ and $X$ and get the coefficient of $Z$, denoted by $\hat{\theta}_Y$; second, fit the OLS of $D$ on $Z$ and $X$ and get the coefficient of $Z$, denoted by $\hat{\theta}_D$; third, the indirect least squares estimator is the ratio $ \hat{\tau}_{\text{ils}} =  \hat{\theta}_Y / \hat{\theta}_D.$ 



The two-stage least squares estimator has two steps: first, fit the OLS of $D$ on $Z$ and $X$ and obtain the fitted vector $\hat{D}$; second, fit the OLS of $Y$ on $\hat{D}$ and $X$ and obtain the coefficient of $\hat{D}$, denoted by $\hat{\tau}_{\text{tsls}}$. 

Many textbooks claim that $ \hat{\tau}_{\text{ils}}  = \hat{\tau}_{\text{tsls}}$ without a formal proof. Note that this is a linear algebra fact without assuming any modeling assumptions. We can verify this using the following simple numerical example. 


\begin{verbatim}
> n = 10^5
> u = rnorm(n)
> v = rnorm(n)
> x = matrix(rnorm(n*2), n, 2)
> z = rnorm(n)
> d = z + as.vector(x%*%c(1, 2)) + u
> y = d + as.vector(x%*%c(1, -1)) + u + v
> summary(lm(y ~ d + x))$coef[2]
[1] 1.500528
> summary(lm(y ~ z + x))$coef[2]/summary(lm(d ~ z + x))$coef[2]
[1] 1.001864
> dhat = lm(d ~ z + x)$fitted.values
> summary(lm(y ~ dhat + x))$coef[2]
[1] 1.001864
\end{verbatim}


Now prove that $ \hat{\tau}_{\text{ils}}  = \hat{\tau}_{\text{tsls}}$. 

 

\section{Data analysis: a job training program \citep{schochet2008does}}


\texttt{jobtraining.rtf} contains the description of the data files \texttt{X.csv} and \texttt{Y.csv}. 

\texttt{X.csv} contains the pretreatment covariates; you can view the sampling weight variable \texttt{wgt} as a covariate too. It is generally difficult to deal with sampling weights. Many previous analyses made this simplification. Conduct analyses with and without covariates. 

\texttt{Y.csv} contains the sampling weight, treatment assigned, treatment received, and many post-treatment variables. Therefore, this data contains many outcomes depending on your questions of interest. The data also have many complications. First, some outcomes are missing. Second, unemployed individuals do not have wages or incomes. Third, the outcomes are repeatedly observed over time. When you do the data analysis, please give details about your choice of the questions of interest and estimators. 


 
\section{Data analysis: \citet{card1993using}}

\citet{card1993using} used the geographic variation in college proximity to estimate the return to schooling. The treatment is education and the outcome is log wage. The instrumental variable is the college proximity. 
\texttt{card.csv} is a slightly modified version of the data from Card's homepage with detailed explanations of the variable names in \texttt{code\_bk.txt}.

You can dichotomize the education variable and infer the LATE. How do you choose the threshold for the dichotomization? Are the results sensitive to your choice? Conduct an analysis with covariates. 

Without  dichotomizing the education variable, you can use the standard two-stage least squares estimator. Compare the results to the above analysis.

What if the return of education is nonlinear? Do the data provide information for us to test the nonlinearity?



\section{Data analysis: \citet{efron1991compliance}}

\citet{efron1991compliance} was one of the early studies dealing with noncomppliance under the potential outcomes framework. The original randomized experiment, the Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT), was designed to evaluate the effect of the drug cholestyramine on cholesterol levels.
In the dataset \texttt{EF.csv}, the first column contains the binary indicators for treatment and control, the second column contains the proportions of the nominal cholestyramine dose actually taken, the last three columns are cholesterol levels.
Note that the individuals did not know whether they were assigned to cholestyramine or to the placebo, but differences in adverse side effects could induce differences in compliance behavior by treatment status. All individuals were assigned the same nominal dose of the drug or placebo, for the same time period.
Column 3, $C_3$, was taken prior to a communication about the benefits of a low- cholesterol diet, Column 4, $C_4,$ was taken after this suggestion, but prior to the random assignment to cholestyramine or placebo, and Column 5, $C_5$,  an average of post-randomization cholesterol readings, averaged over two-month readings for a period of time averaging 7.3 years for all the individuals in the study. \citet{efron1991compliance} used the change in cholesterol level as the final outcome of interest, defined as $C_5 - 0.25C_3 - 0.75C_4$. The original paper contains more detailed descriptions. 
 

This dataset is more complicated than the noncompliance problem discussed in class. You can analyze it based on your understanding of the problem, but you need to justify your choice of method. There is no gold-standard solution for this problem. 

\bibliographystyle{apalike}
\bibliography{causal}

\end{document}



