y <- rank(y)
for (i in 1:length(y)){
if (treatment[i] == 1){
r = r + y[i]
}
}
return(c(taus = tau, alignedRank = r))
}
# Here we obtain the obs. values
tau_pSRE = c()
for (i in 1:4){
stratum = floor(pscore*i) + 1
obsValue <- stat_SRE(stratum, z, y)
tau_pSRE = c(tau_pSRE, obsValue[1])
}
ggplot()+
theme_bw() +
geom_point(aes(x = 1:4, y = tau_pSRE), color = 'maroon', size = 2) +
geom_line(aes(x = 1:4, y = tau_pSRE), color = 'maroon', size = 1)
# Matching Estimator (Bias-Corrected)
tau_mbc = c()
se_tau = c()
for (i in 1:20)
{
model = Match(y, z, x, estimand = "ATE", M = i, BiasAdjust = T)
tau_mbc = c(tau_mbc, model$est)
se_tau = c(se_tau, model$se)
}
ggplot()+
theme_bw() +
geom_point(aes(x = 1:20, y = tau_mbc), color = 'maroon', size = 2) +
geom_line(aes(x = 1:20, y = tau_mbc), color = 'maroon', size = 1)
library("car")
library("Matching")
## experimental data
lalonde = read.csv("cps1re74.csv", sep = " ")
y = lalonde$re78
z = lalonde$treat
x = as.matrix(lalonde[, c("age", "educ", "black",
"hispan", "married", "nodegree",
"re74", "re75")])
## analysis the randomized experiment via
# Lin's Estimator
xc = scale(x)
linols = lm(y ~ z + xc + z*xc)
tau_Lin = linols$coefficients[2]
round(summary(linols)$coef[2, ], 4)
sqrt(hccm(linols)[2, 2])
# Regression Imputation Shall return the same results as Lin
model1 = lm(y[z == 1]~x[z == 1,])
model0 = lm(y[z == 0]~x[z == 0,])
tau_reg = mean(cbind(1, x) %*% model1$coefficients - cbind(1, x) %*% model0$coefficients)
tau_Lin - tau_reg
# Propensity score stratification
pscore = glm(z ~ x, family = binomial)$fitted.values
tau_pSRE = c()
for (i in 2:5){
stratum = floor(pscore*i) + 1
obsValue <- stat_SRE(stratum, z, y)
tau_pSRE = c(tau_pSRE, obsValue[1])
}
tau_pSRE
# IPW estimator
# With no truncation
truncpscore = c(0,1)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_1 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_1 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# With certain truncation
truncpscore = c(0.1,0.9)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_2 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_2 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# Doubly Robust Estimator
outcome1 = glm(y ~ x, weights = z, family = gaussian)$fitted.values
outcome0 = glm(y ~ x, weights = (1 - z), family = gaussian)$fitted.values
res1 = y - outcome1
res0 = y - outcome0
tau_dr = mean(outcome1 - outcome0) + mean(z*res1/pscore - (1 - z)*res0/(1 - pscore))
print(paste("Lin's estimator is ", tau_Lin, sep = ""))
print(paste("Regression Imputation gives us an estimate same as Lin's ", tau_reg, sep = ""))
print(paste("pscore stratification's estimator is ", tau_pSRE, sep = ""))
print(paste("IPW estimator (hovic-thompson) without truncation is ",ipw_1, " and the hajek estimator is ",ipw_hajek_1 ,sep = ""))
print(paste("IPW estimator (hovic-thompson) with truncation is ",ipw_2, " and the hajek estimator is ",ipw_hajek_2 ,sep = ""))
print(paste("The doubly robust estimator is ", tau_dr))
# Propensity score stratification
pscore = glm(z ~ x, family = binomial(link = "probit"))$fitted.values
tau_pSRE = c()
for (i in 2:5){
stratum = floor(pscore*i) + 1
obsValue <- stat_SRE(stratum, z, y)
tau_pSRE = c(tau_pSRE, obsValue[1])
}
# IPW estimator
# With no truncation
truncpscore = c(0,1)
pscore = glm(z ~ x, family = binomial(link = "probit"))$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_1 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_1 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# With certain truncation
truncpscore = c(0.1,0.9)
pscore = glm(z ~ x, family = binomial(link = "probit"))$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_2 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_2 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# Doubly Robust Estimator
outcome1 = glm(y ~ x, weights = z, family = gaussian)$fitted.values
outcome0 = glm(y ~ x, weights = (1 - z), family = gaussian)$fitted.values
res1 = y - outcome1
res0 = y - outcome0
tau_dr = mean(outcome1 - outcome0) + mean(z*res1/pscore - (1 - z)*res0/(1 - pscore))
print("If we fit e(x) by probit model,")
print(paste("Lin's estimator is ", tau_Lin, sep = ""))
print(paste("Regression Imputation gives us an estimate same as Lin's ", tau_reg, sep = ""))
print(paste("pscore stratification's estimator is ", tau_pSRE, sep = ""))
print(paste("IPW estimator (hovic-thompson) without truncation is ",ipw_1, " and the hajek estimator is ",ipw_hajek_1 ,sep = ""))
print(paste("IPW estimator (hovic-thompson) with truncation is ",ipw_2, " and the hajek estimator is ",ipw_hajek_2 ,sep = ""))
print(paste("The doubly robust estimator is ", tau_dr))
print("The doubly robust estimator is the one closest to the golden rule estimation.")
library(MatchIt)
data <- read.csv("FDA-Carpenter.csv")
# We perform similar data treatment
# The democrat is the senate is the treatment indicator, acttime is Y, and others are covariate.
## rescaling
data$hospdisc <- data$hospdisc/100000
data$natreg <- data$natreg/100
data$stafcder <- data$stafcder/100
data$prevgenx <- data$prevgenx/100
data$hhosleng <- data$hhosleng/10
data$condavg3 <- data$condavg3/10
data$orderent <- data$orderent/10
data$vandavg3 <- data$vandavg3/10
data$wpnoavg3 <- data$wpnoavg3/100
z <- data$demsnmaj
y <- data$acttime
x <- as.matrix(data %>%
dplyr::select(-demsnmaj, -acttime))
## analysis the randomized experiment via
# Lin's Estimator
xc = scale(x)
linols = lm(y ~ z + xc + z*xc)
tau_Lin = linols$coefficients[2]
round(summary(linols)$coef[2, ], 4)
sqrt(hccm(linols)[2, 2])
# Regression Imputation Shall return the same results as Lin
model1 = lm(y[z == 1]~x[z == 1,])
model0 = lm(y[z == 0]~x[z == 0,])
tau_reg = mean(cbind(1, x) %*% model1$coefficients - cbind(1, x) %*% model0$coefficients)
# Propensity score stratification
pscore = glm(z ~ x, family = binomial)$fitted.values
tau_pSRE = c()
for (i in 2:5){
stratum = floor(pscore*i) + 1
obsValue <- stat_SRE(stratum, z, y)
tau_pSRE = c(tau_pSRE, obsValue[1])
}
tau_pSRE
# IPW estimator
# With no truncation
truncpscore = c(0,1)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_1 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_1 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# With certain truncation
truncpscore = c(0.1,0.9)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_2 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_2 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# Doubly Robust Estimator
outcome1 = glm(y ~ x, weights = z, family = gaussian)$fitted.values
outcome0 = glm(y ~ x, weights = (1 - z), family = gaussian)$fitted.values
res1 = y - outcome1
res0 = y - outcome0
tau_dr = mean(outcome1 - outcome0) + mean(z*res1/pscore - (1 - z)*res0/(1 - pscore))
print(paste("Lin's estimator is ", tau_Lin, sep = ""))
print(paste("Regression Imputation gives us an estimate same as Lin's ", tau_reg, sep = ""))
print(paste("pscore stratification's estimator is ", tau_pSRE, sep = ""))
print(paste("IPW estimator (hovic-thompson) without truncation is ",ipw_1, " and the hajek estimator is ",ipw_hajek_1 ,sep = ""))
print(paste("IPW estimator (hovic-thompson) with truncation is ",ipw_2, " and the hajek estimator is ",ipw_hajek_2 ,sep = ""))
print(paste("The doubly robust estimator is ", tau_dr))
data <- read.csv("Visibility-Koch.csv")
data <- subset(data, subset=c(repman==1 & voter==1))
data <- na.omit(data.full)
y = data$prcanid
z = 1 - data$rvisman
x = data %>%
dplyr::select("repcan1", "goppty", "rideo", "rproj", "repft", "aware") %>%
as.matrix
## analysis the randomized experiment via
# Lin's Estimator
xc = scale(x)
linols = lm(y ~ z + xc + z*xc)
tau_Lin = linols$coefficients[2]
round(summary(linols)$coef[2, ], 4)
sqrt(hccm(linols)[2, 2])
# Regression Imputation Shall return the same results as Lin
model1 = lm(y[z == 1]~x[z == 1,])
model0 = lm(y[z == 0]~x[z == 0,])
tau_reg = mean(cbind(1, x) %*% model1$coefficients - cbind(1, x) %*% model0$coefficients)
# Propensity score stratification
pscore = glm(z ~ x, family = binomial)$fitted.values
tau_pSRE = c()
for (i in 2:5){
stratum = floor(pscore*i) + 1
obsValue <- stat_SRE(stratum, z, y)
tau_pSRE = c(tau_pSRE, obsValue[1])
}
tau_pSRE
# IPW estimator
# With no truncation
truncpscore = c(0,1)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_1 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_1 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# With certain truncation
truncpscore = c(0.1,0.9)
pscore = glm(z ~ x, family = binomial)$fitted.values
pscore = pmax(truncpscore[1], pmin(truncpscore[2], pscore))
ipw_2 = mean(z*y/pscore - (1 - z)*y/(1 - pscore))
ipw_hajek_2 = mean(z*y/pscore)/mean(z/pscore) - mean((1 - z)*y/(1 - pscore))/mean((1 - z)/(1 - pscore))
# Doubly Robust Estimator
outcome1 = glm(y ~ x, weights = z, family = gaussian)$fitted.values
outcome0 = glm(y ~ x, weights = (1 - z), family = gaussian)$fitted.values
res1 = y - outcome1
res0 = y - outcome0
tau_dr = mean(outcome1 - outcome0) + mean(z*res1/pscore - (1 - z)*res0/(1 - pscore))
print(paste("Lin's estimator is ", tau_Lin, sep = ""))
print(paste("Regression Imputation gives us an estimate same as Lin's ", tau_reg, sep = ""))
# Note that there could be Na values as stratums of pscores might not always include enough control and treatment observations
print(paste("pscore stratification's estimator is ", tau_pSRE, sep = ""))
print(paste("IPW estimator (hovic-thompson) without truncation is ",ipw_1, " and the hajek estimator is ",ipw_hajek_1 ,sep = ""))
print(paste("IPW estimator (hovic-thompson) with truncation is ",ipw_2, " and the hajek estimator is ",ipw_hajek_2 ,sep = ""))
print(paste("The doubly robust estimator is ", tau_dr))
ATT.est = function(z, y, x, out.family = gaussian, Utruncpscore = 1)
{
## sample size
nn  = length(z)
nn1 = sum(z)
## fitted propensity score
pscore   = glm(z ~ x, family = binomial)$fitted.values
pscore   = pmin(Utruncpscore, pscore)
odds.pscore = pscore/(1 - pscore)
## fitted potential outcomes
outcome0 = glm(y ~ x, weights = (1 - z),
family = out.family)$fitted.values
## regression imputation estimator
ace.reg0 = lm(y ~ z + x)$coef[2]
ace.reg  = mean(y[z==1]) - mean(outcome0[z==1])
## propensity score weighting estimator
ace.ipw0 = mean(y[z==1]) -
mean(odds.pscore*(1 - z)*y)*nn/nn1
ace.ipw  = mean(y[z==1]) -
mean(odds.pscore*(1 - z)*y)/mean(odds.pscore*(1 - z))
## doubly robust estimator
res0     = y - outcome0
ace.dr   = ace.reg - mean(odds.pscore*(1 - z)*res0)*nn/nn1
return(c(ace.reg0, ace.reg, ace.ipw0, ace.ipw, ace.dr))
}
ObsCausal.ATT = function(z, y, x, n.boot = 10^2,
out.family = gaussian, Utruncpscore = 1)
{
point.est  = ATT.est(z, y, x, out.family, Utruncpscore)
## nonparametric bootstrap
n.sample   = length(z)
x          = as.matrix(x)
boot.est   = replicate(n.boot,
{id.boot = sample(1:n.sample, n.sample, replace = TRUE)
ATT.est(z[id.boot], y[id.boot], x[id.boot, ],
out.family, Utruncpscore)})
boot.se    = apply(boot.est, 1, sd)
res        = rbind(point.est, boot.se)
rownames(res) = c("est", "se")
colnames(res) = c("reg0", "reg", "HT", "Hajek", "DR")
return(res)
}
n.sim   = 100
ATT0    = rep(0, n.sim)
ATT     = matrix(0, 5, n.sim)
SEboot  = matrix(0, 5, n.sim)
n       = 200
## simulation with correct models
## parallel y1 and y0
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 2, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## nonparallel y1 and y0
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Baseline: simulation with correct models
## Wrong Model for y1 and y0 but correct model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
realbeta.y1 = c(2, 3, 4)
realbeta.y0 = c(100, 101, 102)
y1      = rnorm(n, x1%*%realbeta.y1)
y0      = rnorm(n, x1%*%realbeta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Case 2:
## Correct Model for y1 and y0 but wrong model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/n
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Case 2:
## Correct Model for y1 and y0 but wrong model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 3, 4)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Case 2:
## Correct Model for y1 and y0 but wrong model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 0, 0)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Case 2:
## Correct Model for y1 and y0 but wrong model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
realpscore = 1(1 + exp(-as.vector(x1 %*% c(0,0,0))))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
## Case 2:
## Correct Model for y1 and y0 but wrong model for propensity score
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
realpscore = 1/(1 + exp(-as.vector(x1 %*% c(0,0,0))))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
y1      = rnorm(n, x1%*%beta.y1)
y0      = rnorm(n, x1%*%beta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
## Case 3:
## Wrong model for both y0/y1 and pscore
for(r in 1:n.sim)
{
x       = matrix(rnorm(n*2), n, 2)
x1      = cbind(1, x)
beta.z  = c(0, 1, 1)
pscore  = 1/(1 + exp(- as.vector(x1%*%beta.z)))
realpscore = 1/(1 + exp(-as.vector(x1 %*% c(0,0,0))))
z       = rbinom(n, 1, pscore)
beta.y1 = c(1, 2, 1)
beta.y0 = c(1, 1, 1)
realbeta.y1 = c(2, 3, 4)
realbeta.y0 = c(100, 101, 102)
y1      = rnorm(n, x1%*%realbeta.y1)
y0      = rnorm(n, x1%*%realbeta.y0)
y       = z*y1 + (1 - z)*y0
ATT0[r] = mean(y1[z==1]) - mean(y0[z==1])
causaleffect = ObsCausal.ATT(z, y, x)
ATT[, r]     = causaleffect[1, ]
SEboot[, r]  = causaleffect[2, ]
}
apply(ATT, 1, mean) - mean(ATT0)
apply(ATT, 1, sd)
apply(SEboot, 1, mean)
plot(1:100, ATT[1,])
ggplot() +
geom_density(aes(y = ATT[1,]))
ggplot() +
geom_density(aes(x = ATT[1,]))
ggplot() + theme_bw() +
geom_density(aes(x = ATT))
ggplot() + theme_bw() +
geom_density(aes(x = ATT[2,]))
ggplot() + theme_bw() +
geom_density(aes(x = ATT[3,]))
ggplot() + theme_bw() +
geom_density(aes(x = ATT[4,]))
ggplot() + theme_bw() +
geom_density(aes(x = ATT[5,]))
ggplot() + theme_bw() +
geom_density(aes(x = ATT[5,]), color = "maroon")
ggplot() + theme_bw() +
geom_density2d(aes(x = ATT[5,]), color = "maroon")
ggplot() + theme_bw() +
geom_density2d(aes(y = ATT[5,]), color = "maroon")
ggplot() + theme_bw() +
geom_density(aes(x = ATT[5,]), color = "maroon")
ggplot() + theme_bw() +
geom_density(aes(x = ATT[5,] - mean(ATT0)), color = "maroon") + labs(x = "Doubly Robust Estimator")
