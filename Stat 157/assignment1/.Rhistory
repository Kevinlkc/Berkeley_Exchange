Tauhat   = rep(0, MC)
{
zperm       = sample(z)
Tauhat[mc]  = t.test(y ~ zperm, var.equal = TRUE)$statistic
Student[mc] = t.test(y ~ zperm, var.equal = FALSE)$statistic
Wilcox[mc]  = wilcox.test(y ~ zperm)$statistic
Ks[mc]      = ks.test(y[zperm == 1], y[zperm == 0])$statistic
}
{
zperm       = sample(z)
Tauhat[mc]  = t.test(y ~ zperm, var.equal = TRUE)$statistic
Student[mc] = t.test(y ~ zperm, var.equal = FALSE)$statistic
Wilcox[mc]  = wilcox.test(y ~ zperm)$statistic
Ks[mc]      = ks.test(y[zperm == 1], y[zperm == 0])$statistic
}
for(mc in 1:MC){
zperm       = sample(z)
Tauhat[mc]  = t.test(y ~ zperm, var.equal = TRUE)$statistic
Student[mc] = t.test(y ~ zperm, var.equal = FALSE)$statistic
Wilcox[mc]  = wilcox.test(y ~ zperm)$statistic
Ks[mc]      = ks.test(y[zperm == 1], y[zperm == 0])$statistic
}
par(mfrow = c(2, 2), mar = c(4,1,1,1), mgp = c(1.5, 0.5, 0))
hist(Tauhat, col = "grey",
border = FALSE, freq = FALSE,
xlab = expression(t[eqvar]),
ylab = "",
main = "", yaxt = "n")
tauhat = t.test(y ~ z, var.equal = TRUE)$statistic
abline(v = tauhat)
mean(Tauhat <= tauhat)
xx = seq(-5, 5, 0.01)
yy = dnorm(xx)
lines(yy ~ xx)
hist(Student, col = "grey",
border = FALSE, freq = FALSE,
xlab = expression(t[uneqvar]),
ylab = "",
main = "", yaxt = "n")
student = t.test(y ~ z, var.equal = FALSE)$statistic
abline(v = student)
mean(Student <= student)
lines(yy ~ xx)
hist(Wilcox, col = "grey",
border = FALSE, freq = FALSE,
xlab = expression(W),
ylab = "",
main = "", yaxt = "n")
W = wilcox.test(y ~ z)$statistic
abline(v = W)
mean(Wilcox <= W)
mean.null = nn1*(nn - nn1 + 1)/2
var.null  = nn1*(nn - nn1)*(nn + 1)/12
se.null   = sqrt(var.null)
xx        = seq(mean.null - 3*se.null, mean.null + 3*se.null, 1)
yy        = dnorm(xx, mean.null, se.null)
lines(yy ~ xx)
hist(Ks, col = "grey",
border = FALSE, freq = FALSE,
xlab = expression(D),
ylab = "",
main = "", yaxt = "n")
D = ks.test(y[z == 1], y[z == 0])$statistic
abline(v = D)
mean(Ks >= D)
## approximate tests, easy implementation in R
asym.pv = c(t.test(y ~ z, var.equal = TRUE)$p.value,
t.test(y ~ z, var.equal = FALSE)$p.value,
wilcox.test(y ~ z)$p.value,
ks.test(y[z == 1], y[z == 0])$p.value)
t.test(y ~ z, var.equal = FALSE)$p.value
library(R.utils)
library(foreign)
library(tidyverse)
library(tidyr)
library(dplyr)
library(Matching)
data(lalonde)
View(lalonde)
result <- lm(re78~.-treat, data = lalonde)
summary(result)
y <- result$residuals
z <- lalonde$treat
temp = sample(z)
z
temp
?t.test
data(lalonde)
result <- lm(re78~.-treat, data = lalonde)
z <- lalonde$treat
y <- result$residuals
# Monte-Carlo Simulation of data
MC = 10^3
Tauhat   = rep(0, MC)
Student  = rep(0, MC)
Wilcox   = rep(0, MC)
Ks       = rep(0, MC)
tau = t.test(y ~ z, var.equal = TRUE)$statistic
t = t.test(y ~ z, var.equal = FALSE)$statistic
w = wilcox.test(y ~ z)$statistic
ks = ks.test(y[z == 1], y[z == 0])$statistic
extreme_tau = 0
extreme_t = 0
extreme_w = 0
extreme_ks = 0
for(mc in 1:MC){
zperm = sample(z)
temptau = t.test(y ~ zperm, var.equal = TRUE)$statistic
tempt = t.test(y ~ zperm, var.equal = FALSE)$statistic
tempw = wilcox.test(y ~ zperm)$statistic
tempks = ks.test(y[zperm == 1], y[zperm == 0])$statistic
if (abs(temptau) > abs(tau)){
extreme_tau <- extreme_tau + 1
}
if (abs(tempt) > abs(t)){
extreme_t <- extreme_t + 1
}
if (abs(tempw) > abs(w)){
extreme_w <- extreme_w + 1
}
if (abs(tempks) > abs(ks)){
extreme_ks <- extreme_ks + 1
}
}
result <- lm(re78~-treat, data = lalonde)
library(R.utils)
library(foreign)
library(tidyverse)
library(tidyr)
library(dplyr)
library(Matching)
dat <- read.table("cps1re74.csv",header=T)
# unemployed
dat$u74 <- as.numeric(dat$re74==0)
dat$u75 <- as.numeric(dat$re75==0)
## linear regression on the outcome
lmoutcome = lm(re78 ~ ., data = dat)
summary(lmoutcome)$coef
lmoutcome$coefficients['treat']
lmoutcome = lm(re78 ~ treat, data = dat)
summary(lmoutcome)$coef
alpha <- 0.05
positive <- 0
negative <- 0
# The main idea here is to use bit-operation to perform the loop.
# For each variable j, the index we created in listI[[1]][j]
# determined whether it shall be included in our lm.
for (i in 0:1023){
binaryI <- intToBin(i)
strI <- as.character(binaryI)
listI <- strsplit(strI, "")
modelSpecification <- "re78 ~ treat"
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-'re78', -'treat')
# The model specification is hence decided and updated
# according to the different values of i
for (j in 1:nchar(strI)){
if (listI[[1]][j] == "1"){
modelSpecification <- paste(modelSpecification, "+", colnames(ind_dat)[j])
}
}
lmtemp <- lm(modelSpecification, data = dat)
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] > 0){
positive <- positive + 1
}
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] < 0){
negative <- negative + 1
}
}
# The main idea here is to use bit-operation to perform the loop.
# For each variable j, the index we created in listI[[1]][j]
# determined whether it shall be included in our lm.
for (i in 0:1023){
binaryI <- intToBin(i)
strI <- as.character(binaryI)
listI <- strsplit(strI, "")
modelSpecification <- "re78 ~ treat"
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-re78, -treat)
# The model specification is hence decided and updated
# according to the different values of i
for (j in 1:nchar(strI)){
if (listI[[1]][j] == "1"){
modelSpecification <- paste(modelSpecification, "+", colnames(ind_dat)[j])
}
}
lmtemp <- lm(modelSpecification, data = dat)
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] > 0){
positive <- positive + 1
}
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] < 0){
negative <- negative + 1
}
}
?select
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-"re78", "-treat")
View(dat)
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-re78, -treat)
library(dplyr)
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-re78, -treat)
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-re78)
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-"re78")
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
dat
View(dat)
dat
head(dat)
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- lalonde %>%
select(-"re78")
lalonde
library(R.utils)
library(foreign)
library(tidyverse)
library(tidyr)
library(dplyr)
#library(Matching)
dat <- read.table("cps1re74.csv",header=T)
# unemployed
dat$u74 <- as.numeric(dat$re74==0)
dat$u75 <- as.numeric(dat$re75==0)
## linear regression on the outcome
lmoutcome = lm(re78 ~ ., data = dat)
lmoutcome$coefficients['treat']
lmoutcome = lm(re78 ~ treat, data = dat)
alpha <- 0.05
positive <- 0
negative <- 0
# filter the dependent variable and treatment to ensure the 1-1 mapping
# between our index and the variable
ind_dat <- dat %>%
select(-"re78", -"treat")
# The main idea here is to use bit-operation to perform the loop.
# For each variable j, the index we created in listI[[1]][j]
# determined whether it shall be included in our lm.
for (i in 0:1023){
binaryI <- intToBin(i)
strI <- as.character(binaryI)
listI <- strsplit(strI, "")
modelSpecification <- "re78 ~ treat"
# The model specification is hence decided and updated
# according to the different values of i
for (j in 1:nchar(strI)){
if (listI[[1]][j] == "1"){
modelSpecification <- paste(modelSpecification, "+", colnames(ind_dat)[j])
}
}
lmtemp <- lm(modelSpecification, data = dat)
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] > 0){
positive <- positive + 1
}
if (summary(lmtemp)$coefficients['treat','Pr(>|t|)'] < alpha
& lmtemp$coefficients['treat'] < 0){
negative <- negative + 1
}
}
resume = read.csv("resume.csv")
# Subsetting
male_resume <- resume %>%
filter(sex == "male")
female_resume <- resume %>%
filter(sex == "female")
male_table = table(male_resume$race, male_resume$call)
male_table
fisher.test(male_table)
female_table = table(female_resume$race, female_resume$call)
female_table
fisher.test(female_table)
library(Matching)
data(lalonde)
result <- lm(re78~ -treat, data = lalonde)
z <- lalonde$treat
y <- result$residuals
# Monte-Carlo Simulation of data
MC = 10^3
Tauhat   = rep(0, MC)
Student  = rep(0, MC)
Wilcox   = rep(0, MC)
Ks       = rep(0, MC)
tau = t.test(y ~ z, var.equal = TRUE)$statistic
t = t.test(y ~ z, var.equal = FALSE)$statistic
w = wilcox.test(y ~ z)$statistic
ks = ks.test(y[z == 1], y[z == 0])$statistic
extreme_tau = 0
extreme_t = 0
extreme_w = 0
extreme_ks = 0
for(mc in 1:MC){
zperm = sample(z)
temptau = t.test(y ~ zperm, var.equal = TRUE)$statistic
tempt = t.test(y ~ zperm, var.equal = FALSE)$statistic
tempw = wilcox.test(y ~ zperm)$statistic
tempks = ks.test(y[zperm == 1], y[zperm == 0])$statistic
if (abs(temptau) > abs(tau)){
extreme_tau <- extreme_tau + 1
}
if (abs(tempt) > abs(t)){
extreme_t <- extreme_t + 1
}
if (abs(tempw) < abs(w)){
extreme_w <- extreme_w + 1
}
if (abs(tempks) > abs(ks)){
extreme_ks <- extreme_ks + 1
}
}
x <- seq(1,10,1)
y <- seq(2,20,2)
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sigma_1-sigma_2
# As long as the sign of x', y' are the same, the equation holds.
x <- seq(1,10,1)
y[10] <- 2
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sigma_1-sigma_2
y <- seq(2,20,2)
x[10] <- 1
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sigma_1-sigma_2
# Monte-Carlo Simulation
current_coef <- lm(re78~., data = lalonde)
current_coef <- lm(re78~., data = lalonde)['treat']
View(current_coef)
current_coef <- lm(re78~., data = lalonde)[['treat']]
current_coef <- lm(re78~., data = lalonde)
current_coef
current_coef <- lm(re78~., data = lalonde)$coefficients$treat
current_coef <- lm(re78~., data = lalonde)$coefficients['treat']
extreme_coef <- 0
library(R.utils)
library(foreign)
library(tidyverse)
library(tidyr)
library(dplyr)
#library(Matching)
# Monte-Carlo Simulation
??rnorm
# Monte-Carlo Simulation
??norm
# Monte-Carlo Simulation
??nrand
# Monte-Carlo Simulation
??rand
# Monte-Carlo Simulation
?rnorm
# Monte-Carlo Simulation
Before <- rnorm(100,0,1)
Before
stderr(Before)
sd(Before)
se(Before)
Treatment_effect <- rnorm(100,1,1)
Treatment_effect <- rnorm(50,1,1)
# Monte-Carlo Simulation
# Assume that we already have the science table
Before <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(50,1,1) * treat
Control_effect <- rnorm(50,0,1) * treat
# Monte-Carlo Simulation
# Assume that we already have the science table
x <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(50,1,1) * treat
Control_effect <- rnorm(50,0,1) * treat
y <- x + Treatment_effect + Control_effect
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sigma_2 <- median(y-x)
y-x
# Monte-Carlo Simulation
# Assume that we already have the science table
x <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(100,1,1) * treat
Control_effect <- rnorm(100,0,1) * treat
y <- x + Treatment_effect + Control_effect
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
y-x
treat
# Monte-Carlo Simulation
# Assume that we already have the science table
x <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(100,1,1) * treat
Control_effect <- rnorm(100,0,1) * (1-treat)
y <- x + Treatment_effect + Control_effect
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
# Monte-Carlo Simulation
# Assume that we already have the science table
Before <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(100,1,1) * treat
Control_effect <- rnorm(100,0,1) * (1-treat)
After <- Before + Treatment_effect + Control_effect
y <- After[1:50]
x <- After[51:100]
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
# Monte-Carlo Simulation
# Assume that we already have the science table
MC <- 1e3
# Monte-Carlo Simulation
# Assume that we already have the science table
MC <- 1e3
sum_of_squares_1 <- 0
sum_of_squares_2 <- 0
for (mc in 1:MC){
Before <- rnorm(100,0,1)
treat <- c(rep(1,50), rep(0,50))
Treatment_effect <- rnorm(100,1,1) * treat
Control_effect <- rnorm(100,0,1) * (1-treat)
After <- Before + Treatment_effect + Control_effect
y <- After[1:50]
x <- After[51:100]
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sum_of_squares_1 <- sum_of_squares_1 + (sigma_1-1)^2
sum_of_squares_2 <- sum_of_squares_2 + (sigma_2-1)^2
}
# Monte-Carlo Simulation
# Assume that we already have the science table
MC <- 1e3
sum_of_squares_1 <- 0
sum_of_squares_2 <- 0
for (mc in 1:MC){
Before <- rnorm(1000,0,1)
treat <- c(rep(1,500), rep(0,500))
Treatment_effect <- rnorm(1000,1,1) * treat
Control_effect <- rnorm(1000,0,1) * (1-treat)
After <- Before + Treatment_effect + Control_effect
y <- After[1:500]
x <- After[501:1000]
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sum_of_squares_1 <- sum_of_squares_1 + (sigma_1-1)^2
sum_of_squares_2 <- sum_of_squares_2 + (sigma_2-1)^2
}
# Monte-Carlo Simulation
# Assume that we already have the science table
MC <- 1e4
sum_of_squares_1 <- 0
sum_of_squares_2 <- 0
for (mc in 1:MC){
Before <- rnorm(1000,0,1)
treat <- c(rep(1,500), rep(0,500))
Treatment_effect <- rnorm(1000,1,1) * treat
Control_effect <- rnorm(1000,0,1) * (1-treat)
After <- Before + Treatment_effect + Control_effect
y <- After[1:500]
x <- After[501:1000]
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sum_of_squares_1 <- sum_of_squares_1 + (sigma_1-1)^2
sum_of_squares_2 <- sum_of_squares_2 + (sigma_2-1)^2
}
# Monte-Carlo Simulation
# Assume that we already have the science table
MC <- 1e4
sum_of_squares_1 <- 0
sum_of_squares_2 <- 0
sum_1 <- 0
sum_2 <- 0
for (mc in 1:MC){
Before <- rnorm(1000,0,1)
treat <- c(rep(1,500), rep(0,500))
Treatment_effect <- rnorm(1000,1,1) * treat
Control_effect <- rnorm(1000,0,1) * (1-treat)
After <- Before + Treatment_effect + Control_effect
y <- After[1:500]
x <- After[501:1000]
sigma_1 <- median(y) - median(x)
sigma_2 <- median(y-x)
sum_of_squares_1 <- sum_of_squares_1 + (sigma_1-1)^2
sum_of_squares_2 <- sum_of_squares_2 + (sigma_2-1)^2
sum_1 <- sum_1 + sigma_1
sum_2 <- sum_2 + sigma_2
}
mean(test<4)
test <- c(1,2,3,4,5)
mean(test<4)
