ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "blue")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "diamond")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "light green")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "light blue")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "dark blue")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "dark pink")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "pink")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange")
# Q1: Fit a model with, say, degree 4
model <- lm(y~poly(x, degree = 5, raw = T))
stargazer(model)
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values))
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8)
# Q2: Plot more!
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8))
}
# Q2: Plot more!
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8)) + labs(title = paste("Polynomial Fit with Degree",i, sep = " "))
}
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8)) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8)) + labs(title = paste("Polynomial Fit with Degree",i, sep = " "))
ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8)) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")
# Q2: Plot more!
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")))
}
# Q2: Plot more!
RSS = c()
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")))
RSS = c(RSS, sum(model$residuals^2))
}
ggplot() + theme_bw() + geom_point(aes(x = 1:10, y = RSS), color = "maroon")
# Q2: Plot more!
RSS = c()
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")))
RSS = c(RSS, sum(model$residuals^2))
print("The RSS of the model with degrees", i, " is", RSS[i])
}
# Q2: Plot more!
RSS = c()
for (i in 1:10){
model <- lm(y~poly(x, degree = i, raw = T))
print(ggplot() + theme_bw() + geom_point(aes(x = x, y = model$fitted.values), color = "maroon") + geom_point(aes(x = x, y = y), color = "orange") + geom_line(aes(x = x, y = model$fitted.values), color = "maroon", alpha = 0.8) + labs(title = paste("Polynomial Fit with Degree",i, sep = " ")))
RSS = c(RSS, sum(model$residuals^2))
print(paste("The RSS of the model with degrees", i, " is", RSS[i], sep = ""))
}
ggplot() + theme_bw() + geom_line(aes(x = 1:10, y = RSS), color = "maroon")
# Problem 6
data(Boston)
trainingSet <- Boston %>% dplyr::select(dis, nox)
x = trainingSet$dis
y = trainingSet$nox
# Use Cross-Validation
trainingSet <- trainingSet %>%
mutate(instant = 1:nrow(trainingSet), fold = 0)
tempdata <- trainingSet
for (i in 1:5){
num = 780
if (i == 5){num = 778}
temp <-  sample_n(tempdata, num)
tempdata <- tempdata %>%
filter(!(instant %in% temp$instant))
trainingSet[trainingSet$instant %in% temp$instant,] <- trainingSet %>%
filter(instant %in% temp$instant) %>%
mutate(fold = i)
}
for (i in 1:5){
num = 100
if (i == 5){num = 106}
temp <-  sample_n(tempdata, num)
tempdata <- tempdata %>%
filter(!(instant %in% temp$instant))
trainingSet[trainingSet$instant %in% temp$instant,] <- trainingSet %>%
filter(instant %in% temp$instant) %>%
mutate(fold = i)
}
View(trainingSet)
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model = lm(nox ~ poly(dis, degree = j, raw = T), data = train)
yfit = cbind(1, poly(test$dis, degree = j, raw = T)) %*% model$coefficients
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
apply(MSE, 1, mean)
apply(MSE, 2, mean)
which.min(apply(MSE, 2, mean))
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
set.seed(1)
# Use Cross-Validation
trainingSet <- trainingSet %>%
mutate(instant = 1:nrow(trainingSet), fold = 0)
tempdata <- trainingSet
for (i in 1:5){
num = 100
if (i == 5){num = 106}
temp <-  sample_n(tempdata, num)
tempdata <- tempdata %>%
filter(!(instant %in% temp$instant))
trainingSet[trainingSet$instant %in% temp$instant,] <- trainingSet %>%
filter(instant %in% temp$instant) %>%
mutate(fold = i)
}
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model = lm(nox ~ poly(dis, degree = j, raw = T), data = train)
yfit = cbind(1, poly(test$dis, degree = j, raw = T)) %*% model$coefficients
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
set.seed(12345)
# Use Cross-Validation
trainingSet <- trainingSet %>%
mutate(instant = 1:nrow(trainingSet), fold = 0)
tempdata <- trainingSet
for (i in 1:5){
num = 100
if (i == 5){num = 106}
temp <-  sample_n(tempdata, num)
tempdata <- tempdata %>%
filter(!(instant %in% temp$instant))
trainingSet[trainingSet$instant %in% temp$instant,] <- trainingSet %>%
filter(instant %in% temp$instant) %>%
mutate(fold = i)
}
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model = lm(nox ~ poly(dis, degree = j, raw = T), data = train)
yfit = cbind(1, poly(test$dis, degree = j, raw = T)) %*% model$coefficients
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
set.seed(11111)
# Use Cross-Validation
trainingSet <- trainingSet %>%
mutate(instant = 1:nrow(trainingSet), fold = 0)
tempdata <- trainingSet
for (i in 1:5){
num = 100
if (i == 5){num = 106}
temp <-  sample_n(tempdata, num)
tempdata <- tempdata %>%
filter(!(instant %in% temp$instant))
trainingSet[trainingSet$instant %in% temp$instant,] <- trainingSet %>%
filter(instant %in% temp$instant) %>%
mutate(fold = i)
}
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model = lm(nox ~ poly(dis, degree = j, raw = T), data = train)
yfit = cbind(1, poly(test$dis, degree = j, raw = T)) %*% model$coefficients
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
?bs
??bs
??bs()
install.packages("splines")
library("splines")
quantile(x)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(tidyr)
library(MASS)
library(stargazer)
library(splines)
lm(nox~bs(dis,knots=c(2.1,3.2,5.2)),data=trainingSet)
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2)),data=trainingSet)
pred=predict(model,newdata=list(dis = dis.grid),se=T)
pred=predict(model,newdata=list(dis),se=T)
pred=predict(model,newdata=list(trainingSet$dis),se=T)
pred=predict(model,newdata=trainingSet$dis,se=T)
model$fitted.values
plot(dis,model$fitted.values,col="gray")
plot(model$dis,model$fitted.values,col="gray")
plot(x,model$fitted.values,col="gray")
plot(x,y)
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
lines(x,model$fit+2*model$se ,lty="dashed")
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2)),data=trainingSet)
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
lines(x,model$fit+2*model$se ,lty="dashed")
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
lines(x,(model$fit +2*model$se) ,lty="dashed")
model$fit +2*model$se
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2)),data=trainingSet, se = T)
summary(model)
summary(model)$se
summary(model)$Std.Err
temp = summary(model)
View(temp)
temp = summary(model)$coef
View(temp)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
attach(trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
lines(x,(model$fit +2*preds$se) ,lty="dashed")
lines(x,(model$fit -2*preds$se) ,lty="dashed")
plot(x, model$fitted, col="gray")
lines(x,model$fit,lwd=2)
plot(x, preds$fitted, col="gray")
lines(x,preds$fit,lwd=2)
preds$fit
plot(x, preds$fitted, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
plot(x, preds$fitted, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
plot(x, y, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
keep.image()
image.keep()
for (i in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = 1),data=trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
print(plot(x, y, col="gray"))
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
}
for (i in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = i),data=trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
print(plot(x, y, col="gray"))
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
}
for (i in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = i),data=trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
plot(x, y, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
}
for (i in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = i),data=trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
plot(x, y, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
labs(i)
}
for (i in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = i),data=trainingSet)
preds=predict(model,newdata=list(dis=seq(from = min(dis), to = max(dis))),se=TRUE)
plot(x, y, col="gray")
lines(seq(from = min(dis), to = max(dis)),preds$fit,lwd=2)
lines(seq(from = min(dis), to = max(dis)),(preds$fit +2*preds$se) ,lty="dashed")
lines(seq(from = min(dis), to = max(dis)),(preds$fit -2*preds$se) ,lty="dashed")
title(paste("Spline With Degree ", i, sep = ""))
}
# Note that in the plot we only choose some sample points,
# presenting a broken line instead of a curve
preds
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = pred(model, newdata = list(test$dis))
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, newdata = list(test$dis))
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
quantile(x)
quantile(x)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(1,2.1,3.2,5.2,13), degree = j), data=train)
yfit = predict(model, newdata = test$dis)
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
quantile(x)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(1,2.1,3.2,5.2,13), degree = j), data=train)
yfit = predict(model, newdata = list(test$dis))
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, newdata = list(test$dis))
yfit
mean((test$nox - yfit)^2)
yfit = predict(model, newdata = list(test$dis))
View(model)
?predict
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, newdata = list(test$dis))
?predict
mean((test$nox - yfit)^2)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, test$dis)
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, newdata = list(test$dis))
?predict
mean((test$nox - yfit)^2)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- lm(nox~bs(dis,knots=c(2.1,3.2,5.2), degree = j), data=train)
yfit = predict(model, list(test$dis))
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- smooth.spline(x = train$dis, y = train$nox, df = j)
yfit = predict.smooth.spline(model, test$dis)
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 1:10){
model <- smooth.spline(x = train$dis, y = train$nox, df = j)
yfit = predict(model, test$dis)
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
?smooth.spline
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
?smooth.spline
model <- smooth.spline(x = train$dis, y = train$nox)
yfit = predict(model, test$dis)
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
model <- smooth.spline(x = train$dis, y = train$nox)
yfit = predict(model, test$dis)$fit
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
model <- smooth.spline(x = train$dis, y = train$nox)
yfit = predict(model, test$dis)$fit
temp <- predict(model, test$dis)
View(temp)
temp <- predict(model, test$dis)
View(temp)
model <- smooth.spline(x = train$dis, y = train$nox)
temp <- predict(model, test$dis)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
model <- smooth.spline(x = train$dis, y = train$nox)
yfit = predict(model, test$dis)$y
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
View(MSE)
model <- smooth.spline(x = train$dis, y = train$nox)
temp <- predict(model, test$dis)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
model <- smooth.spline(x = train$dis, y = train$nox, df = j)
yfit = predict(model, test$dis)$y
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 1:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
model <- smooth.spline(x = train$dis, y = train$nox)
temp <- predict(model, test$dis)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 10)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
model <- smooth.spline(x = train$dis, y = train$nox, df = j)
yfit = predict(model, test$dis)$y
MSE[i,j] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 2:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
model <- smooth.spline(x = train$dis, y = train$nox)
temp <- predict(model, test$dis)
# Cross-validation
MSE = matrix(0, nrow = 5, ncol = 9)
for (i in 1:5){
train = trainingSet %>% filter(fold != i)
test = trainingSet %>% filter(fold == i)
for (j in 2:10){
model <- smooth.spline(x = train$dis, y = train$nox, df = j)
yfit = predict(model, test$dis)$y
MSE[i,j-1] = mean((test$nox - yfit)^2)
}
}
which.min(apply(MSE, 2, mean))
# The best model is the 3rd degree polynomial
ggplot() + geom_line(aes(x = 2:10, y = apply(MSE, 2, mean)), color = "maroon") + theme_bw()
