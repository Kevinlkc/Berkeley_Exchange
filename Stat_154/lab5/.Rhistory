scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
# Original function
set.seed(55555)
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
f <- function(X, e = 1){
epsilon = rnorm(length(X),0,e)
return(0.04*X^4 -0.4*X^3 +6*X-3+epsilon)
}
Y = f(X)
result <- lm(Y~X)
# Plotting our data
ggplot() + theme_bw() +
geom_point(aes(x= X, y = Y)) +
geom_abline(slope = result$coefficients[2], intercept = result$coefficients[1], color = 'red') +
geom_line(aes(X_true,Y_true)) +
labs(
x = "t",
y = "predicted values"
)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
# n = 6
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
# Now we calculate our training and test MSE
# to put everything in a loop, we choose to use the poly function here，note that in this function we standardize our data so that the result won't seem tremendous.
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0.0001)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0.0001)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - cbind(1,(poly(X_test,degree = deg, raw = T))) %*%result$coefficients)^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,], na.rm = TRUE)
plotdata$MSE_test[i] = mean(MSE_test[i,], na.rm = TRUE)
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'), size = 1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'), size = 1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
# Learn the impact of noise,first, consider the case that there's simply no noise
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - (cbind(1,poly(X_test,degree = deg, raw = T)) %*% result$coefficients))^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,], na.rm = TRUE)
plotdata$MSE_test[i] = mean(MSE_test[i,], na.rm = TRUE)
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'),size=1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'),size=1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
# Original function
set.seed(55555)
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
f <- function(X, e = 1){
epsilon = rnorm(length(X),0,e)
return(0.04*X^4 -0.4*X^3 +6*X-3+epsilon)
}
Y = f(X)
result <- lm(Y~X)
# Plotting our data
ggplot() + theme_bw() +
geom_point(aes(x= X, y = Y)) +
geom_abline(slope = result$coefficients[2], intercept = result$coefficients[1], color = 'red') +
geom_line(aes(X_true,Y_true)) +
labs(
x = "t",
y = "predicted values"
)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
# n = 6
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
# Now we calculate our training and test MSE
# to put everything in a loop, we choose to use the poly function here，note that in this function we standardize our data so that the result won't seem tremendous.
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0.0001)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0.0001)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - cbind(1,(poly(X_test,degree = deg, raw = T))) %*%result$coefficients)^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,], na.rm = TRUE)
plotdata$MSE_test[i] = mean(MSE_test[i,], na.rm = TRUE)
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'), size = 1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'), size = 1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
# Learn the impact of noise,first, consider the case that there's simply no noise
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - (cbind(1,poly(X_test,degree = deg, raw = T)) %*% result$coefficients))^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,], na.rm = TRUE)
plotdata$MSE_test[i] = mean(MSE_test[i,], na.rm = TRUE)
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'),size=1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'),size=1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Learn the impact of noise: Assume there's a little noise, not that much
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0.00001)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0.00001)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - (cbind(1,poly(X_test,degree = deg, raw = T)) %*% result$coefficients))^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,], na.rm = TRUE)
plotdata$MSE_test[i] = mean(MSE_test[i,], na.rm = TRUE)
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'), size = 1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'), size = 1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
# Now we calculate our training and test MSE
# to put everything in a loop, we choose to use the poly function here，note that in this function we standardize our data so that the result won't seem tremendous.
X_test <- runif(100,-4,6)
Y_test <- f(X_test, 0.0001)
MSE_test <- matrix(rep(0,8000), nrow = 8)
MSE_train <- matrix(rep(0,8000), nrow = 8)
for (i in 1:1000){
X_sample <- runif(10,-4,6)
Y_sample <- f(X_sample, 0.0001)
for (deg in 1:8){
X <- poly(X_sample, degree = deg, raw = T)
result <- lm(Y_sample~X)
MSE_train[deg,i] <- mean((result$residuals)^2)
MSE_test[deg,i] <- mean((Y_test - cbind(1,(poly(X_test,degree = deg, raw = T))) %*%result$coefficients)^2, na.rm = TRUE)
}
}
plotdata <- data.frame(index = 1:8, MSE_train = rep(0,8), MSE_test = rep(0,8))
for (i in 1:8){
plotdata$MSE_train[i] = mean(MSE_train[i,])
plotdata$MSE_test[i] = mean(MSE_test[i,])
}
plotdata
plotdata %>%
ggplot() + theme_bw() +
geom_line(aes(x = index, y = MSE_train, color = 'MSE_train'), size = 1) +
geom_line(aes(x = index, y = MSE_test, color = 'MSE_test'), size = 1) +
scale_color_manual(values = c('MSE_train' = 'red', 'MSE_test' = 'blue'))
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0.1)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
set.seed(55555)
X <- runif(10,-4,6)
X_true = seq(-4,6,0.01)
Y_true <- 0.04*X_true^4 -0.4*X_true^3 +6*X_true-3
Y = f(X, 0.1)
result <- lm(Y~X)
# Graph of Overfitting
# n = 2
X1 <- cbind(X,X^2)
model_1 <- lm(Y~X1)
# Store the coefficients
Plotdata1 <- cbind(1,X_true, X_true^2)
predicted1 <- Plotdata1 %*% model_1$coefficients
# n = 4
X2 <- cbind(X,X^2,X^3,X^4)
model_2 <- lm(Y~X2)
# Store the coefficients
Plotdata2 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4)
predicted2 <- Plotdata2 %*% model_2$coefficients
X3 <- cbind(X,X^2,X^3,X^4, X^5,X^6)
model_3 <- lm(Y~X3)
# Store the coefficients
Plotdata3 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6)
predicted3 <- Plotdata3 %*% model_3$coefficients
# n = 8
X4 <- cbind(X,X^2,X^3,X^4, X^5,X^6,X^7,X^8)
model_4 <- lm(Y~X4)
# Store the coefficients
Plotdata4 <- cbind(1,X_true, X_true^2, X_true^3, X_true^4, X_true^5, X_true^6, X_true^7, X_true^8)
predicted4 <- Plotdata4 %*% model_4$coefficients
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
# Plot them together
ggplot() + theme_bw() +
geom_line(aes(x = X_true, y = Y_true, color = 'True')) +
geom_line(aes(x = X_true, y = predicted1, color = 'n=2')) +
geom_line(aes(x = X_true, y = predicted2, color = 'n=4')) +
geom_line(aes(x = X_true, y = predicted3, color = 'n=6')) +
geom_line(aes(x = X_true, y = predicted4, color = 'n=8')) +
scale_y_continuous(expand = c(0.05,0.05)) +
scale_x_continuous(expand = c(0.05,0.05))
